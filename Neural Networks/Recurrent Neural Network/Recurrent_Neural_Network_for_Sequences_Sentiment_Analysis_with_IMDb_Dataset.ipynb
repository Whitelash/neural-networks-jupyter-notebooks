{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "dD30p8Us08T0",
        "fcbP-FAT08X2",
        "BUw7tNcK08Zo",
        "1hlcNGsk08bA",
        "Uv0OyrhL08bS",
        "Yi7vmiaZ08dZ",
        "O6cr1fsv08eb",
        "AzNV536U08e7",
        "RuKuhHMR39vi",
        "Hwcbfm6_DAP7"
      ]
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oll7K9CY08RV"
      },
      "source": [
        "Sentiment Analysis - positive or Negative => binary classification problem\n",
        "IMDb -- Movie reviews dataset\n",
        "Recurrent NN-- Process sequences of data --NlP\n",
        "* time series\n",
        "* Text in sentences\n",
        "recurrent -- the NN contains loopss - output of a given layer becomes the input to the same layer in the next word in aa sequence of words for text sequence\n",
        "* loops in RNNs help them to learn relationships among the data in the sequence.\n",
        "Good -- on its own is a posivtive sentiment\n",
        "Not good has a negative sentiment,, Not is earlier in the seauence\n",
        "RNN do consider the relationships among earlier and later data in the sequence. here the words that determine sentiment are adjacent. But whn considering text's meaning there can  be many words to consider and abitary  nunmber of words between them.\n",
        "\n",
        "Long short- Term Memory (LSTM) -- layer that makes the neural network recurrent.\n",
        "\n",
        "- Predictive text input\n",
        "- Sentiment Analysis\n",
        "- Responding to questions with predicted best answers\n",
        "- Inter- language translation\n",
        "- automated video closed captioning -- speech recognition\n",
        "- speech synthesis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pv7s4SQz08R2"
      },
      "source": [
        "#Loading the IMDb Movie Review Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMdzRRfe08R7"
      },
      "source": [
        "from tensorflow.keras.datasets import imdb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZ8uD7sl08SH"
      },
      "source": [
        "88,000  unique words in a dataset\n",
        "* you can specifyy the number of unique words to import -- training and testing data\n",
        "* usually 10,000 most frquent occuring words are used\n",
        "* Due to systemmemeory limitations and training on cpu -- GPU,, TPU\n",
        "-- the more data the longer it takes to train-- it may produce better models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylFT2kGD08SI"
      },
      "source": [
        "#load_data  replaces any words outside the  10,000 with a placeholder\n",
        "number_of_words=10000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9JSe-Y808SZ"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5UaQogu08Si"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lp0hB_tq08Sp"
      },
      "source": [
        "#save the np.load\n",
        "np_load_old=np.load"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MENyRAkA08Sv"
      },
      "source": [
        "#modify the defalut parameters of np.load\n",
        "# *a is a list , **k is an object -- argc\n",
        "np.load=lambda *a,**k: np_load_old(*a, allow_pickle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIlGRiQk08S1"
      },
      "source": [
        "(x_train,y_train),(x_test,y_test)= imdb.load_data(num_words=number_of_words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Em3B1D0508S8"
      },
      "source": [
        "#x-test and x_xtrain apear as 1 dimentional -- Numpy array of objects(list of intergers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hL2ABn2X08TD",
        "outputId": "b18533a6-2c99-4392-8bb2-a5d722c146f7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sg0C6Qrh08TI",
        "outputId": "d61d1da7-5cf0-4ecb-eea7-43421835f93c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2t_EME6k08TN",
        "outputId": "abf10360-f18b-4975-ef81-fc1e44d5f39e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNsddXy_08TU",
        "outputId": "fc2e7eb4-3fdd-4b15-b8b9-82df67f91473",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLMCnw6A08Tf",
        "outputId": "4cdffa3e-6066-4274-fddc-6e851edcfc52",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 0, ..., 0, 1, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dD30p8Us08T0"
      },
      "source": [
        "# Data Exploration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLjsU9oa08UH"
      },
      "source": [
        "The arrays y_train and y_test -1D with 0s(negative) and 1s(postive). the x_train and x_test are list og intergers each represenig one reviews's contents.\n",
        "Keras models require numeric data -- IMDb data is preprocessed for you"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ME0zkR7m08UK",
        "outputId": "35143b8c-c7a7-4bec-f48a-958b5b97f39e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%pprint # toggle better printing so thats elements do not display vertically"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pretty printing has been turned OFF\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWL8IYMj08UX",
        "outputId": "8f8b8907-1f0e-4735-b739-4d75d2e125a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x_train[123]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 307, 5, 1301, 20, 1026, 2511, 87, 2775, 52, 116, 5, 31, 7, 4, 91, 1220, 102, 13, 28, 110, 11, 6, 137, 13, 115, 219, 141, 35, 221, 956, 54, 13, 16, 11, 2714, 61, 322, 423, 12, 38, 76, 59, 1803, 72, 8, 2, 23, 5, 967, 12, 38, 85, 62, 358, 99]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6GDban508Ux"
      },
      "source": [
        "to view the original text you need to know the word to which each number corresponds to.\n",
        "The keras dictionary - provides the dictionary that maps words to their indexes.\n",
        "EACH WORDS VALUE IS ITS FREQUENCY OCCURING WORD ... FOR Example randing 1 -- frequently occuring in that dataset\n",
        "-Training and the testing data -- have an offset of3. (1+3) = 4-- most frequently occuring word has a value of 4.\n",
        "the values 0,1,2 are reserved\n",
        "adding (0) -- all the traing /testingmusut have the sam dimentions\n",
        " some reviews may nee d to be padded with a 0 and some shorted\n",
        " start of the sequnce (1) -- a token used by keras internally for learnig purposes\n",
        "\n",
        " unknown word(2) not loaded -- load_data uses 2 for words with freq ranks > than the num-words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33u2SxPw08U6"
      },
      "source": [
        "word_to_index=imdb.get_word_index()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LvGqN0bm08VQ",
        "outputId": "3b887f4c-6f06-4e34-f8a8-7c732629e6e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "word_to_index['great']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "84"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWDhv25A08V8"
      },
      "source": [
        "#great is the 84th most freq word"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OcCKXBKn08WO"
      },
      "source": [
        "#lets\n",
        "index_to_word={index: word for (word, index)in word_to_index.items()}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emVGY1jm08Xm",
        "outputId": "c79ea63b-4c1d-4762-dbe4-8adc0b804304",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "[index_to_word[i] for i in range(1,51)]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['the', 'and', 'a', 'of', 'to', 'is', 'br', 'in', 'it', 'i', 'this', 'that', 'was', 'as', 'for', 'with', 'movie', 'but', 'film', 'on', 'not', 'you', 'are', 'his', 'have', 'he', 'be', 'one', 'all', 'at', 'by', 'an', 'they', 'who', 'so', 'from', 'like', 'her', 'or', 'just', 'about', \"it's\", 'out', 'has', 'if', 'some', 'there', 'what', 'good', 'more']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fcbP-FAT08X2"
      },
      "source": [
        "# Decoding a Movie Review\n",
        "\n",
        "- To decode a review\n",
        "    - i-3 accounts for the frequency ratings offsets in the encoded reviews\n",
        "    - i values 0-2 = ? otherwise should return the word"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbNbstr008Ya",
        "outputId": "c063e4f7-388b-46f6-efb3-d7c5d913da7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "' '.join([index_to_word.get(i-3, '?') for i in x_train[123]])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'? beautiful and touching movie rich colors great settings good acting and one of the most charming movies i have seen in a while i never saw such an interesting setting when i was in china my wife liked it so much she asked me to ? on and rate it so other would enjoy too'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3z8ci-V08ZT",
        "outputId": "3de9f499-7a83-4986-c596-112b1da150c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y_train[123]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BUw7tNcK08Zo"
      },
      "source": [
        "# Data Preparation\n",
        "\n",
        "- Number of words per review varies\n",
        "- Keras requires all samples to have the same dimensions\n",
        "- Prepare the data\n",
        "    - Restrict every review to the same number of words\n",
        "    - Pad some with 0s, truncate others\n",
        "    - pad-sequences function - reshapes the samples and returns a 2D array"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHbGSfdD08Zp"
      },
      "source": [
        "words_per_review = 200"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAG_Gmdm08aA"
      },
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WuHo8wjk08ab"
      },
      "source": [
        "x_train = pad_sequences(x_train, maxlen = words_per_review)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4wj_S5E408ay",
        "outputId": "67e8c038-0103-4abe-be80-8d06f6166fdc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 200)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8uMAC35t08a7",
        "outputId": "fb5b9ff0-9112-4635-a575-d04519f96c38",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   5,   25,  100, ...,   19,  178,   32],\n",
              "       [   0,    0,    0, ...,   16,  145,   95],\n",
              "       [   0,    0,    0, ...,    7,  129,  113],\n",
              "       ...,\n",
              "       [   0,    0,    0, ...,    4, 3586,    2],\n",
              "       [   0,    0,    0, ...,   12,    9,   23],\n",
              "       [   0,    0,    0, ...,  204,  131,    9]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1hlcNGsk08bA"
      },
      "source": [
        "# Data Preparation - Cont.\n",
        "\n",
        "- Reshape the x_test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svX74Ed008bB"
      },
      "source": [
        "x_test=pad_sequences(x_test, maxlen = words_per_review)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LV9LaTDx08bJ",
        "outputId": "6a412ed1-accc-476a-ea6f-2f8573c04051",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 200)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uv0OyrhL08bS"
      },
      "source": [
        "## Splitting the test data into validation and test data\n",
        "\n",
        "    - Split the 25,000 test samples into 20,000 test samples and 5000 validation samples\n",
        "    - We pass vaalidation samples to the models fit method - validation_data argument\n",
        "        - use the scikit-learn train_test_split function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtEIq4iD08bb"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HoyYYw9h08dC"
      },
      "source": [
        "x_test,x_val,y_test,y_val=train_test_split(x_test,y_test,random_state=11, test_size=0.20)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4X6QjU908dJ",
        "outputId": "557a9b62-e254-442c-d7b7-57a75084c24c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20000, 200)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVma2UAs08dS",
        "outputId": "c43c0448-93e7-4692-b52a-a59bcb1b1b42",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x_val.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5000, 200)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yi7vmiaZ08dZ"
      },
      "source": [
        "# Creating the Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWOBjYF308db"
      },
      "source": [
        "from tensorflow.keras.models import Sequential"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFgceGTR08dn"
      },
      "source": [
        "rnn = Sequential()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2mOjSWx08eJ",
        "outputId": "c2065e08-1366-4f94-e338-618e52c8c43b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "rnn"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.engine.sequential.Sequential object at 0x7f40d8096400>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWYf53Nl08eU"
      },
      "source": [
        "from tensorflow.keras.layers import Dense, LSTM, Embedding"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6cr1fsv08eb"
      },
      "source": [
        "### Adding an Embedding Layer\n",
        "\n",
        "- In our convne example we used one-hot encoding - into categorical data - others 0 and one 1\n",
        "- index values that represent words\n",
        "- 1, 00000000000000000000000000000000000000000000000000000000000000000000000\n",
        "    - 0 100000000000000000000000000000000000000000000000000000000000000000\n",
        "- recall cnn.add(Dense(units=10, activation ='softmax')) - 0,1,2,3,4,5,6,7,8,9 => 0.0003, 0.88...\n",
        "- Will need 10,000 by 10,000 array to represent all the words\n",
        "- 100,000,000 array to represent the words\n",
        "- All would be 0 except 1\n",
        "- all 88,000 +unique words -- 8billion elements\n",
        "\n",
        "- Reduce dimensionality - RNN process Text sequences, use the embedding layer\n",
        "- Each encodes each word in a more compact dense-vector representation\n",
        "- Help RNN - word relations -> this movie is not good --0 this movie is good -- 1\n",
        "    * Predefined word embeddings -- Word2Vec and GloVe\n",
        "        - can load into nn to save training time\n",
        "        - used to add basic word relationships to model smaller amounts of training  data (available)\n",
        "        - Improve model accuracy - by looking at the previous word relations -Transfer Learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udHkbDic08ef"
      },
      "source": [
        "rnn.add(Embedding(input_dim = number_of_words, output_dim = 128, input_length = words_per_review))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9VZyJjkC08eo"
      },
      "source": [
        "- input_dim === Number of unique words\n",
        "- output_dim-- six of the word embedding\n",
        "- input_length== Number of words in each input sample"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhZYca-B08er"
      },
      "source": [
        "# Adding an LSTM Layer\n",
        "rnn.add(LSTM(units = 128, dropout = 0.2, recurrent_dropout=0.2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzNV536U08e7"
      },
      "source": [
        "- Units -- number of neuronsin that layer (the more the neurons the more the network can remember)\n",
        "- length of the sequence - 200 -- and the number of classes to predict -- 2 class - 2-200\n",
        "- dropout- percentage of neurons that are disabled when processing the layer's input and output\n",
        "\n",
        "## Adding Dense Output Layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6NCVBnf52SMP"
      },
      "source": [
        "- We need to reduce the LTSM layer's output to 1 value (result should be one)-\n",
        "\n",
        "+ or - We need te value of 1 for the units arguments\n",
        "- sigmoid activation function - used for bnary classification - reduces arbitrary values into the range 0.0-1.-, producing a probability"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFntRJUb3bcy"
      },
      "source": [
        "rnn.add(Dense(units=1, activation='sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RuKuhHMR39vi"
      },
      "source": [
        "#Compiling the model and display the summary\n",
        "- 'categorical_crossentropy'--'binary_crossentropy'regresssion - 'mean_squared_error'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysYjnokK4NbX"
      },
      "source": [
        "rnn.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8VOtbsr4bDD",
        "outputId": "af7d076c-89f0-4f63-ca89-db1b3ccdaf5d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "rnn.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 200, 128)          1280000   \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 128)               131584    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 1,411,713\n",
            "Trainable params: 1,411,713\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffcReOS-4g14"
      },
      "source": [
        "#Training and Evaluating the model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "niyIF3B_8giT",
        "outputId": "f3545bf8-cb7b-41ef-96ed-87a0e0be89ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 200)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFDgfffq5hyh"
      },
      "source": [
        "-For every Epoch the RNN model takes longer ti train than the CNN (Number of parameters)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKipg0fD5w0Z",
        "outputId": "ae4ee608-2dd9-4458-c429-5466a8027f46",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "rnn.fit(x_train, y_train, epochs=10, batch_size=32, validation_data=(x_test,y_test))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "782/782 [==============================] - 479s 613ms/step - loss: 0.3628 - accuracy: 0.8463 - val_loss: 0.3052 - val_accuracy: 0.8741\n",
            "Epoch 2/10\n",
            "782/782 [==============================] - 489s 626ms/step - loss: 0.2376 - accuracy: 0.9087 - val_loss: 0.3346 - val_accuracy: 0.8696\n",
            "Epoch 3/10\n",
            "782/782 [==============================] - 487s 623ms/step - loss: 0.1806 - accuracy: 0.9325 - val_loss: 0.5050 - val_accuracy: 0.8394\n",
            "Epoch 4/10\n",
            "782/782 [==============================] - 480s 613ms/step - loss: 0.1367 - accuracy: 0.9491 - val_loss: 0.4674 - val_accuracy: 0.8363\n",
            "Epoch 5/10\n",
            "782/782 [==============================] - 481s 615ms/step - loss: 0.1100 - accuracy: 0.9604 - val_loss: 0.4259 - val_accuracy: 0.8605\n",
            "Epoch 6/10\n",
            "782/782 [==============================] - 485s 620ms/step - loss: 0.0885 - accuracy: 0.9680 - val_loss: 0.4980 - val_accuracy: 0.8543\n",
            "Epoch 7/10\n",
            "782/782 [==============================] - 488s 624ms/step - loss: 0.0681 - accuracy: 0.9776 - val_loss: 0.5684 - val_accuracy: 0.8594\n",
            "Epoch 8/10\n",
            "782/782 [==============================] - 491s 628ms/step - loss: 0.0582 - accuracy: 0.9802 - val_loss: 0.5851 - val_accuracy: 0.8536\n",
            "Epoch 9/10\n",
            "782/782 [==============================] - 493s 630ms/step - loss: 0.0449 - accuracy: 0.9859 - val_loss: 0.6246 - val_accuracy: 0.8566\n",
            "Epoch 10/10\n",
            "782/782 [==============================] - 500s 640ms/step - loss: 0.0351 - accuracy: 0.9892 - val_loss: 0.6070 - val_accuracy: 0.8502\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History object at 0x7f40cf0eefd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xU9IfLPosBl"
      },
      "source": [
        "results=rnn.evaluate(x_test, y_test)\n",
        "results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hwcbfm6_DAP7"
      },
      "source": [
        "#Tuning Deep Learning Models\n",
        "Some variables that can affect the model performance\n",
        "- more or less data to train with\n",
        "- more or less data to test with\n",
        "- having more or fewer layers\n",
        "- types of layers you use\n",
        "- order of the layers\n",
        "\n",
        "-Some things that we could tune on our model:\n",
        "- Try differernt amounts of training data- 10,000\n",
        "- Different number of words per review - 200,  300\n",
        "- Different number of neurons in our layers\n",
        "- More layers\n",
        "-  Transfer learning- loading pre-trained word vectors rather learning from scratch\n",
        "* k-fold cross-validation - 10 -fold cross validation ANN - longer time - tuning hyperparameters\n",
        "\n",
        "** Auto-keras"
      ]
    }
  ]
}